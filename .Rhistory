sub(4,2)
}
add(2,4)
add<-function(a,b){
print(a+b)
}
add(add(2,4),add(3,6))
(function(pi=3.14,r)pi*r*r)(r=6)
library("readxl")
getwd()
setwd("D:/R Programs")
getwd()
read.csv("input.csv")
read_excel("C:\\Users\\&umi\\Downloads\\Sample  Superstore (3).xls")
a<-read_excel("C:\\Users\\&umi\\Downloads\\Sample  Superstore (3).xls")
View(a)
smp<-read_excel(file.choose())
smp
View(smp)
head(smp,n=10)
knitr::opts_chunk$set(echo = TRUE)
plot(pressure)
library("sqldf")
sqldf("select * from smp")
View(sqldf("select * from smp"))
View(sqldf("select * from smp limit 10"))
View(sqldf("select count(*) from smp"))
View(sqldf("select max(Profit) from smp"))
View(sqldf("select Region,Segment,Profit from smp
where Region==Central"))
View(sqldf("select Region,Segment,Profit from smp
where Region=='Central'"))
View(sqldf("select * from smp order by Profit"))
View(sqldf("select * from smp group by Profit"))
View(sqldf("select Region,City,Segment from smp where City like 'H%"))
View(sqldf("select Region,City,Segment from smp where City like 'H%'"))
View(sqldf("select Region,City,Segment from smp where City like '%H'"))
View(sqldf("select Region,City,Segment from smp where City like '%h'"))
View(sqldf("select Region,City,Segment from smp where City like '%h%'"))
View(sqldf("select sum(sales) from smp where profit=(select max(profit) from smp)"))
strsplit("hello world","")
x<-"hello world"
strsplit(x," ")
x<-c("abc","def","ghi")
grep("ghi",x)
x<-c("abc","def","ghi","GHI")
grep("ghi",x)
grep("ghi",x,ignore.case=T,value=T)
substr("aashima",2,4)
y<-"hello world"
sub("el","xy",y)
strsplit("hello world","")
strsplit("hello world"," ")
grep("b+",c(abc,xyz,abbc,b))
grep("b+",c("abc","xyz","abbc","b"))
strsplit(c("20-10-2018","19-5-2020"),split="-")
x<-"hello9colud8xy"
strsplit(x,split=[0-9]+)
strsplit(x,split="[0-9]"+)
strsplit(x,split="[0-9]+")
x<-matrix(1:9,nrow=2,ncol=3)
x
x<-matrix(1:9,nrow=3,ncol=3)
x
apply(x,1,sum)
apply(x,2,mean)
library("readxl")
smp<-read_excel(file.choose())
smp
View(smp)
library("sqldf")
sqldf("select count(*) from smp")
sqldf("select Region,segment,Profit where City like %h%")
sqldf("select Region,segment,Profit where City like '%h%'")
sqldf("select Region,segment,Profit from smp where City like '%h%'")
View(sqldf("select sum(sales) from smp where Profit=(select max(Profit) from smp)"))
View(sqldf(select sum(Sales) from smp where Region='Central' or Region='West'))
View(sqldf("select sum(Sales) from smp where Region='Central' or Region='West'"))
View(sqldf("select sum(Sales) from smp where Region in('Central','West'"))
View(sqldf("select sum(Sales) from smp where Region in('Central','West')"))
View(sqldf("select Region,Profit from smp group by Region
having sum(Profit)>0"))
abs(-5)
log(5)
log10(5)
floor(4.2)
ceiling(4.2)
round(3.44,digit=1)
round(3.456,digit=2)
trunc(3.14)
a<-"hello world"
nchar(a)
substr("aashima",2,4)
grep("b*", c("ab+", "bda2", "+ccaa", "ad"),value=F)
#***************************************************
#tapply() function:It helps us to create a subset of a vector and
#then apply some functions to each of the subsets.
#In such cases where we want to break the data into different groups and
#apply specific functions in each of the subgroup
#Syntax: tapply( x, index,  fun )
#x: determines the input vector or an object.
#index: determines the factor vector that helps us distinguish the data.
#fun: determines the function that is to be applied to input data.
data.frame(id=c(1,2,3,4),name=c("john","alex","aryan","ani"),
marks=c(10,20,30,40),section=c('A','B','A','B'))
#***************************************************
#tapply() function:It helps us to create a subset of a vector and
#then apply some functions to each of the subsets.
#In such cases where we want to break the data into different groups and
#apply specific functions in each of the subgroup
#Syntax: tapply( x, index,  fun )
#x: determines the input vector or an object.
#index: determines the factor vector that helps us distinguish the data.
#fun: determines the function that is to be applied to input data.
res<-data.frame(id=c(1,2,3,4),name=c("john","alex","aryan","ani"),
marks=c(10,20,30,40),section=c('A','B','A','B'))
res
res$section
mean1<-factor((res$section),labels=c('A','B'))
mean1
tapply(marks,mean1,mean)
marks<-res$marks
marks
tapply(marks,mean1,mean)
res
res$section
marks<-res$marks
marks
mean1<-factor((res$section),labels=c('Section A','Section B'))
mean1
tapply(marks,mean1,mean)
#******************************************************************
#mapply
mapply(rep, 1:4, 4:1)
mapply(rep, times = 1:4, x = 4:1)
mapply(rep, times = 1:4, MoreArgs = list(x = 42))
x<-c("aashi","aashima","meera","seema")
lapply(x,toupper)
a<-1:3
a<-1:3
fun<-function(x){
x^2
}
lapply(a,fun)
list1<-list(A=c(1,2,3,4),data.frame(x<-1:5,y<-c(10,20,30,40)))
list1<-list(A=c(1,2,3,4),data.frame(x<-1:5,y<-c(10,20,30,40,50)))
list1
list1<-list(A=c(1,2,3,4),data.frame(x=1:5,y=c(10,20,30,40,50)))
list1
lapply(list1,sum)
sapply(1:4,sqrt)
lapply(1:4,sqrt)
#************************************************
out<-numeric(10)
for(i in 1:10){
out[i]<-i^2
}
out
#**************************************************
x<-list(A=1:5,B=6:20,c=1)
sapply(x,length)
#**********************************************
x<-list(A=1:5,B=6:10,c=11:15)
sapply(x,length)
strings <- c("a", "ab", "acb", "accb", "acccb", "accccb")
strings
grep("ac*b", strings, value = TRUE)
grep("ac+b", strings, value = TRUE)
grep("ac?b", strings, value = TRUE)
grep("ac{2}b", strings, value = TRUE)
grep("ac{2,}b", strings, value = TRUE)
grep("ac{2,3}b", strings, value = TRUE)
stringr::str_extract_all(strings, "ac{2,3}b", simplify = TRUE)
grep("ac*b", strings)
grep("ac*b", strings, value = F)
#, handling missing data
#is.na() Function for Finding Missing values
#A logical vector is returned by this function that indicates all #the NA values present.
x<- c(NA, 3, 4, NA, NA, NA)
is.na(x)
#is.nan() Function for Finding Missing values:
x<- c(NA, 3, 4, NA, NA, 0 / 0, 0 / 0)
is.nan(x)
#Removing NA or NaN values
x <- c(1, 2, NA, 3, NA, 4)
d <- is.na(x)
x[!d]
x <- c(1, 2, 0 / 0, 3, NA, 4, 0 / 0)
x
x[! is.na(x)]
# Creating a data frame
df <- data.frame (c1 = 1:8,
c2 = factor (c("B", "A", "B", "C",
"A", "C", "B", "A")))
df
# Filling some NA in data frame
df[4, 1] <- df[6, 2] <- NA
df
na.omit(df)
# Printing all the levels(NA is not considered one)
levels(df$c2)
#handlig missing data
starwars
#handlig missing data
library(dplyr)
starwars
is.na(starwars)
View(is.na(starwars))
a<-c(10,20,NA,30,40,50,NA)
is.na(a)
a<-c(10,20,NA,30,40,50,NA,0/0)
is.na(a)
is.nan(a)
a<-a[!is.na]
a<-!is.na(a)
a
a<-c(10,20,NA,30,40,50,NA,0/0)
is.na(a)
d<-is.na(a)
a[!d]
sum(is.na(a))
na.omit(a)
# Creating a data frame
df <- data.frame (c1 = 1:8,
c2 = factor (c("B", "A", "B", "C",
"A", "C", "B", "A")))
df
# Filling some NA in data frame
df[4, 1] <- df[6, 2] <- NA
df
sum(is.na(df))
na.omit(df)
df<-data.frame(name=c("a","b","c"),age=c(10,20,30),height=c(2,3,4))
df
df[2,1]<-df[3,2]<-NA
df
sum(is.na(df))
na.omit(df)
na.exclude(df)
is.na(df)
x<-is.na(df)
df[!is.na()]
df[!x]
# creating a data frame
tidy_dataframe = data.frame(
S_No = c(1:n),
Group.1 = c(23, 345, 76, 212, 88,
199, 72, 35, 90, 265),
Group.2 = c(117, 89, 66, 334, 90,
101, 178, 233, 45, 200),
Group.3 = c(29, 101, 239, 289, 176,
320, 89, 109, 199, 56))
install.packages("tidyr")
library("tidyr")
messy
n = 10
# creating a data frame
tidy_dataframe = data.frame(
S.No = c(1:n),
Group.1 = c(23, 345, 76, 212, 88,
199, 72, 35, 90, 265),
Group.2 = c(117, 89, 66, 334, 90,
101, 178, 233, 45, 200),
Group.3 = c(29, 101, 239, 289, 176,
320, 89, 109, 199, 56))
tidy_dataframe
long <- tidy_dataframe %>%
gather(Group, Frequency,
Group.1:Group.3)
long
starwars
View(starwars)
filter(!is.na(starwars))
filter(!is.na(height))
filter(!is.na("height"))
filter(starwars,!is.na(height))
starwars%>%gather(color,value,hair_color,eye_color)
View(starwars%>%gather(color,value,hair_color,eye_color))
long <- tidy_dataframe %>%
gather(Group, Frequency,
Group.1:Group.3)
long
View(starwars%>%gather(color,value,hair_color,eye_color,na.rm = T))
View(starwars%>%gather(color,value,hair_color,eye_color))
View(starwars%>%gather(color,value,hair_color,eye_color,na.rm=T))
#2. separate() function: It converts longer data to a wider format.
#The separate() function turns a single character column into multiple
#columns.
long <- tidy_dataframe %>% gather(Group, Frequency,
Group.1:Group.3)
separate_data <- long %>% separate(Group, c("Allotment",
"Number"))
separate_data
#3. unite() function: It merges two columns into one column.
#The unite() function is a convenience function to paste together
#multiple variable values into one. In essence, it combines two
#variables of a single observation into one variable.
# use unite() function to glue
# Allotment and Number columns
unite_data <- separate_data %>%
unite(Group, Allotment,
Number, sep = ".")
# print the new data frame
unite_data
#5. nest() function: It creates a list of data frames containing
#all the nested variables.
df <- tidy_dataframe
df
# nest column Group.1 in
# tidy_dataframe using nest()
df %>% nest(data = c(Group.1))
x <- c("a","b","c","d","e")
y <- c("A","B","C","D","E")
paste(x,y)
#By default, values are separated by a space; you can specify another separator (or
#none at all) with the sep argument:
paste(x,y,sep="-")
paste(x,y,sep="-",collapse="#")
docs<-Corpus(DirSource("D:\old pc data\R Programs\house.csv"))
docs<-Corpus(DirSource("D:\\old pc data\\R Programs\\house.csv"))
library(tm)
docs<-Corpus(DirSource("D:\\old pc data\\R Programs\\house.csv"))
getwd()
docs<-Corpus(DirSource("house.csv"))
docs<-Corpus(DirSource("/house.csv"))
txt<-read.csv(file.choose())
docs<-Corpus(VectorSource(txt))
inspect(docs)
txt<-read.csv(file.choose())
docs<-Corpus(VectorSource(txt))
inspect(docs)
txt<-read.csv(file.choose(),header=TRUE)
docs<-Corpus(VectorSource(txt))
inspect(docs)
docs<-iconv(txt$text)
x<-Corpus(VectorSource(docs))
inspect(x)
inspect(x[1:5]))
inspect(x[1:5])
txt<-read.csv(file.choose(),header=TRUE)
docs<-iconv(txt$text)
x<-Corpus(VectorSource(docs))
inspect(x[1:5])
txt<-read.csv(file.choose(),header=TRUE)
x<-Corpus(VectorSource(txt$Comments))
inspect(x[1:5])
x<-Corpus(VectorSource(txt$sentence))
inspect(x)
x[[1]][1]
#start preprocessing
#convert the text to lower case
x<-tm_map(x,content_transformer(tolower))
x
library(tm)
txt<-read.csv(file.choose(),header=TRUE)
x<-Corpus(VectorSource(txt$sentence))
inspect(x)
x[[1]][1]
#start preprocessing
#convert the text to lower case
x<-tm_map(x,content_transformer(tolower))
#start preprocessing
#convert the text to lower case
x<-tm_map(x,content_transformer(toupper))
#start preprocessing
#convert the text to lower case
x<-tm_map(x,removeNumbers)
x<-Corpus(VectorSource(txt$sentence))
inspect(x)
#start preprocessing
#convert the text to lower case
x<-tm_map(x,content_transformer(tolower))
library(tm)
#start preprocessing
#convert the text to lower case
x<-tm_map(x,content_transformer(tolower))
#start preprocessing
tospace<-content_transformer(function(x,pattern){return(gsub(pattern," ",x))})
tospace
# read file
a=read.csv(file.choose(),header=TRUE)
str(a)
summary(a)
View(a)
# build corpus: collection of doc
# each tweet will be consider as documents
# VectorSource() function
# creates a corpus of
# character vectors
library(tm)
corpus<-iconv(a$text)
corpus<- Corpus(VectorSource(corpus))
inspect(corpus[1:5])
corpus<- tm_map(corpus,tolower)
inspect(corpus[1:5])
corpus<-tm_map(corpus,removePunctuation)# remove puntuations like , .
x<-Corpus(VectorSource(txt$sentence))
inspect(x)
x[[1]][1]
#start preprocessing
lwr<-tm_map(x,content_transformer(tolower))
x<-VCorpus(VectorSource(txt$sentence))
inspect(x)
x[[1]][1]
#start preprocessing
lwr<-tm_map(x,content_transformer(tolower))
lwr
inspect(lwr)
x[[1]][1]
cor<-x[[1]][1]
#start preprocessing
lwr<-tm_map(cor,content_transformer(tolower))
library(tm)
#start preprocessing
lwr<-tm_map(cor,content_transformer(tolower))
lwr
inspect(lwr)
cor<-tm_map(lwr,removeNumbers)
cor
x[[1]][1]
inspect(corpus[1:5])
corpus<- tm_map(corpus,removeNumbers)
inspect(corpus[1:5])
cleanset<-tm_map(corpus,removeWords,stopwords('english'))# remove common words
inspect(cleanset[1:5])
library(tm)
txt<-read.csv(file.choose(),header=TRUE)
corpus<-iconv(txt$sentence)
corp<-iconv(txt$sentence)
corp<-Corpus(VectorSource(corp))
inspect(corp[1:5])
#start preprocessing
lwr<-tm_map(cor,content_transformer(tolower))
#start preprocessing
corp<-tm_map(cor,content_transformer(tolower))
inspect(corp[1:5])
#start preprocessing
corp<-tm_map(cor,content_transformer(tolower))
inspect(corp[1:5])
x <- "I like this! #this, @wheres_my, I like R (v3.2.2) #rrrrrrr2015"
# remove space or tabs
gsub(pattern = "[[:blank:]]", replacement = "", x)
# replace punctuation with whitespace
gsub(pattern = "[[:punct:]]", replacement = " ", x)
# remove alphanumeric characters
gsub(pattern = "[[:alnum:]]", replacement = "", x)
#To find exactly where the pattern exists in a string use regexpr():
x <- c("v.111", "0v.11", "00v.1", "000v.", "00000")
regexpr("v.", x)
#substitute ^ with carrot
sub(pattern = "\\^", "carrot", "My daughter has a ^ with almost every meal!")
string <- c("I sleep 16 hours\n, a day","I sleep 8 hours\n a day.","You sleep how many\t hours ?")
#remove control characters
gsub(pattern = "[[:cntrl:]]+",replacement = " ",x = string)
#remove non graphical characters
gsub(pattern = "[^[:graph:]]+",replacement = "",x = string)
gsub(pattern="[[:upper]]",replacement = "",x)
gsub(pattern="[[:alpha]]",replacement = "",x)
library(quantmod)
#--------------------------------------
#downloading data
#use getSymbols to get data from yahoo or google(default is yahoo)
getSymbols("AAPL")
head(AAPL,n=3)
#-------------------------------------
#Quantmod draw nice charts of following common types:
# line,bars,candlesticks
#-------------------------------
#the line chart displays closing price of the stockSymbols
chartSeries(AAPL,type="line",subset="2007",
theme=chartTheme("white"))
#----------------------------------------------
#the bar chart displays open,high,low,close and
#volume closing price of the stock
#the top of the bar is high and bottom is low
#the left stick is open and right stick is close
#if the close is higher than open,the bar is green, otherwise
#it is in orange color
chartSeries(AAPL,type="bar",subset = '2007-05::2007-06',
theme = chart_theme("white"))
#----------------------------------------------
#the bar chart displays open,high,low,close and
#volume closing price of the stock
#the top of the bar is high and bottom is low
#the left stick is open and right stick is close
#if the close is higher than open,the bar is green, otherwise
#it is in orange color
chartSeries(AAPL,type="bar",subset = '2007-05::2007-06',
theme = chartTheme("white"))
#-------------------
#candlestick chart is very similar to bar chart
#it also displays open,high,low,close and volume colsing price
#of the stock
chartSeries(AAPL,type="candlesticks",subset = '2007-05',
up.col = "white",down.col="black",
theme=chartTheme("white"))
#----------------------------------------------
#bollinger Band
#a channel (or band)is an area that surronds a trend within
#which price movement does not indicate formation of a new trend
chartSeries(AAPL,subset='2007-05::2009-01',
theme=chartTheme("white"))
addBBands(n=20,sd=2)
#----------------------------------------------
#the bar chart displays open,high,low,close and
#volume closing price of the stock
#the top of the bar is high and bottom is low
#the left stick is open and right stick is close
#if the close is higher than open,the bar is green, otherwise
#it is in orange color
chartSeries(AAPL,type="bar",subset = '2007-05::2007-06',
theme = chartTheme("white"))
